{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归\n",
    "## 什么是回归分析（Regression Analysis）\n",
    "- 根据数据，确定两种或两种以上变量间的互相依赖的定量关系\n",
    "- 函数表达式 $y = f(x_1,x_2···x_n)$\n",
    "\n",
    "## 如何计算线性方程\n",
    "- 线性回归默认函数：$y=ax + b$\n",
    "- 计算损失函数：$minimize{\\begin{Bmatrix} \\frac{1}{2m} \\sum_{i=1}^{m}{(y'_i - y_i)^2} \\end{Bmatrix}}$\n",
    "- 得出关于 a,b 方程：$minimize(j) = \\frac{1}{2m} \\sum_{i=1}^{m}{(y'_i - y_i)^2} = \\frac{1}{2m} \\sum_{i=1}^{m}{(ax_i + b - y_i)^2} = g(a,b)$\n",
    "- 梯度下降法：寻找极小值的一种方法。通过向函数上当前点对应梯度（或者是近似梯度）的反方向的规定步长距离点进行迭代搜索，直到在极小点收敛\n",
    "  - 从一个初始点开始,计算该点对应的目标函数的梯度(也就是函数在该点的斜率)。\n",
    "  - 然后沿着梯度的负方向(也就是函数下降最快的方向)移动一个步长距离,到达新的点。\n",
    "  - 重复第1-2步,直到梯度(斜率)接近0,也就是到达了函数的局部极小点。\n",
    "  - 具体公式：$j = f(p) \\qquad p_{i+1} = p_i - \\alpha\\dfrac{\\partial}{\\partial p_i}f(p_i)$\n",
    "- 具体代码实现方程\n",
    "  - $\\begin{Bmatrix} temp_a = a - \\alpha\\dfrac{\\partial}{\\partial a}g(a,b) = a - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}{(ax_i + b - y_i)x_i}  \\\\ \\\\ temp_b = b - \\alpha\\dfrac{\\partial}{\\partial a}g(a,b) = b - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}{(ax_i + b - y_i)} \\\\ a = temp_a \\\\ b = temp_b \\\\ \\end{Bmatrix}$\n",
    "- 评判模型\n",
    "  - 均方误差（越小越好）：$MSE = \\frac{1}{m} \\sum_{i=1}^{m}{(y'_i - y_i)^2}$\n",
    "\n",
    "  - R方值（越接近1越好）：$R_2 = 1- \\frac{\\sum_{i=1}^{m}{(y'_i - y_i)^2}}{\\sum_{i=1}^{m}{(y'_i - \\overline{y_i})^2}} = 1 - \\frac{MSE}{方差}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
